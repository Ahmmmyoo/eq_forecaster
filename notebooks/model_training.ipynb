{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import pandas as pd\n",
    "# url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "\n",
    "# params = {\n",
    "#     \"format\": \"geojson\",\n",
    "#     \"starttime\": \"2023-01-01\",\n",
    "#     \"endtime\": \"2023-12-31\",\n",
    "#     \"minmagnitude\": 5\n",
    "# }\n",
    "# response = requests.get(url, params=params, timeout=1000)\n",
    "# data = response.json()\n",
    "# features = data.get(\"features\", [])\n",
    "# print(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "def fetch_usgs_data(start_date, end_date, min_magnitude=2.5):\n",
    "    url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "    \n",
    "    try:\n",
    "        params = {\n",
    "            \"format\": \"geojson\",\n",
    "            \"starttime\": start_date,\n",
    "            \"endtime\": end_date,\n",
    "            \"minmagnitude\": min_magnitude\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, timeout=1000)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        features = data.get(\"features\", [])\n",
    "        \n",
    "        records = []\n",
    "        for feature in features:\n",
    "            props = feature[\"properties\"]\n",
    "            geometry = feature[\"geometry\"][\"coordinates\"]\n",
    "            records.append({\n",
    "                \"time\": pd.to_datetime(props[\"time\"], unit=\"ms\"),\n",
    "                \"latitude\": geometry[1],\n",
    "                \"longitude\": geometry[0],\n",
    "                \"depth\": geometry[2],\n",
    "                \"magnitude\": props[\"mag\"],\n",
    "                \"event_occurred\": 1  \n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(records)\n",
    "        negative_samples = pd.DataFrame({\n",
    "            \"latitude\": np.random.uniform(df['latitude'].min(), df['latitude'].max(), 100),\n",
    "            \"longitude\": np.random.uniform(df['longitude'].min(), df['longitude'].max(), 100),\n",
    "            \"depth\": np.random.uniform(df['depth'].min(), df['depth'].max(), 100),\n",
    "            \"magnitude\": np.zeros(100),\n",
    "            \"event_occurred\": 0\n",
    "        })\n",
    "        \n",
    "        df = pd.concat([df, negative_samples], ignore_index=True)\n",
    "        return df\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching USGS data: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_classification_data(df, lookback=30, test_size=0.2):\n",
    "    features = ['latitude', 'longitude', 'depth', 'magnitude']\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df[features])\n",
    "    target = df['event_occurred'].values\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - lookback):\n",
    "        X.append(scaled_data[i:i+lookback])\n",
    "        y.append(target[i+lookback])\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_probability_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, activation='relu', input_shape=input_shape, return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.LSTM(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Probability output\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy', tf.keras.metrics.AUC()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_probability_model(model, X_test, y_test):\n",
    "    y_pred_proba = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    metrics = {\n",
    "        'Log Loss': log_loss(y_test, y_pred_proba),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'Accuracy': np.mean(y_pred == y_test),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_earthquake_probability(model, input_data, scaler):\n",
    "    scaled_input = scaler.transform(input_data)\n",
    "    scaled_input = scaled_input.reshape(1, -1, 4)\n",
    "    probability = model.predict(scaled_input)[0][0]\n",
    "    return probability * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/Dev/analytics_and_modeling/eq_forecaster/notebooks/eq_forecast_env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.9640 - auc_6: 0.6536 - loss: 0.3496 - val_accuracy: 0.9576 - val_auc_6: 1.0000 - val_loss: 0.0627\n",
      "Epoch 2/2\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9754 - auc_6: 0.9961 - loss: 0.0377 - val_accuracy: 0.9960 - val_auc_6: 1.0000 - val_loss: 0.0084\n",
      "Model saved at: ../src/server/neural_network/eq_model\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "Model Performance Metrics:\n",
      "Log Loss: 0.01568338938877876\n",
      "ROC AUC: 0.9998477234658139\n",
      "Accuracy: 0.9951534733441034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/Dev/analytics_and_modeling/eq_forecaster/notebooks/eq_forecast_env/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step\n",
      "\n",
      "Probability of Earthquake at (35.0, -117.0): 51.77%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def main_earthquake_probability_prediction(\n",
    "    start_date='2023-12-01', \n",
    "    end_date='2024-01-01', \n",
    "    min_magnitude=2.5, \n",
    "    lookback=30\n",
    "):\n",
    "    earthquake_data = fetch_usgs_data(start_date, end_date, min_magnitude)\n",
    "    if earthquake_data.empty:\n",
    "        print(\"No earthquake data retrieved.\")\n",
    "        return None\n",
    "\n",
    "    X_train, X_test, y_train, y_test, scaler = prepare_classification_data(\n",
    "        earthquake_data, lookback=lookback\n",
    "    )\n",
    "    \n",
    "    model = build_probability_model(input_shape=(lookback, 4))\n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        validation_split=0.2, \n",
    "        epochs=2, \n",
    "        batch_size=32, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model_save_path = \"../src/server/neural_network/eq_model\"\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    model.save(f\"{model_save_path}.keras\")\n",
    "    print(f\"Model saved at: {model_save_path}\")\n",
    "    \n",
    "    metrics = evaluate_probability_model(model, X_test, y_test)\n",
    "    print(\"Model Performance Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    example_input = np.array([[35.0, -117.0, 10.0, 4.0]])\n",
    "    earthquake_probability = predict_earthquake_probability(model, example_input, scaler)\n",
    "    \n",
    "    print(f\"\\nProbability of Earthquake at (35.0, -117.0): {earthquake_probability:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'model': model, \n",
    "        'metrics': metrics, \n",
    "        'scaler': scaler\n",
    "    }\n",
    "\n",
    "result = main_earthquake_probability_prediction()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eq_forecast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
